{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will explain how to extract the locations of trees from aerial imagery and create a shapefile containing points representing these tree locations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing neccesery libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import tifffile\n",
    "from affine import Affine\n",
    "import os\n",
    "from rasterio.windows import Window\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString, Polygon\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import detectree as dtr\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from  rasterio.features import geometry_mask\n",
    "from shapely.geometry import mapping, Polygon\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "import warnings\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    c = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduction aerial imagery resolution:** \n",
    "\n",
    " \n",
    "Certainly, the level of detail and accuracy in aerial imagery is directly linked to its spatial resolution. A resolution of 0.5 meters per pixel is generally sufficient for tree extraction, but superior results come with higher spatial resolutions. However, higher resolution implies longer training times for tree detection models, creating a trade-off between accuracy and processing speed. Moreover, the processing time is not just determined by resolution but also by the volume of available aerial imagery. More imagery results in longer processing times. To manage this, reducing spatial resolution minimizes the raw data. All the above must be carefully considered based on the specific project requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [03:44<02:51, 17.18s/it]"
     ]
    }
   ],
   "source": [
    "def save_rescaled(tif_path,  output_dir, new_resolution = tuple(c['raw_data']['desired_resolution']), current_resolution= tuple(c['raw_data']['current_resolution'])):\n",
    "\n",
    "    \"\"\"\n",
    "    Rescale a GeoTIFF image while preserving georeferencing and save it as a new GeoTIFF.\n",
    "\n",
    "    Parameters:\n",
    "    - tif_path (str): The path to the input GeoTIFF file.\n",
    "    - output_dir (str): The directory where the rescaled GeoTIFF file will be saved.\n",
    "    - new_resolution (tuple, optional): The desired new resolution as a tuple of (y_resolution, x_resolution) in units per pixel. Default is (0.45, 0.45).\n",
    "    - current_resolution (tuple, optional): The current resolution of the input GeoTIFF as a tuple of (y_resolution, x_resolution) in units per pixel. Default is (0.15, 0.15).\n",
    "    \n",
    "    Returns:\n",
    "    - output_tiff (str): The path to the saved rescaled GeoTIFF.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the ratio of the old and new resolutions along X and Y axes\n",
    "    resolution_ratio_x = current_resolution[1] / new_resolution[1]\n",
    "    resolution_ratio_y = current_resolution[0] / new_resolution[0]\n",
    "    \n",
    "    # Build the output file path for the rescaled GeoTIFF\n",
    "    output_tiff = os.path.join(output_dir, os.path.basename(tif_path)[:-4] + '_rescaled.tif')\n",
    "\n",
    "    # Open the original GeoTIFF file using rasterio and obtain metadata\n",
    "    with rio.open(tif_path) as src:\n",
    "        # Read image data and metadata\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "        # Create an Affine transformation matrix with the updated resolution\n",
    "        new_transform = Affine(transform.a / resolution_ratio_x, transform.b, transform.c,\n",
    "                        transform.d, transform.e / resolution_ratio_y, transform.f)\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    img = cv2.imread(tif_path)\n",
    "\n",
    "    # Convert the image from BGR to RGB format\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Calculate new dimensions based on resolution ratio\n",
    "    new_width = int(img.shape[1] * resolution_ratio_x)\n",
    "    new_height = int(img.shape[0] * resolution_ratio_y)\n",
    "\n",
    "    # Perform the image rescaling using bilinear interpolation\n",
    "    resized = cv2.resize(img_rgb, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Define a new profile for the rescaled GeoTIFF\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'dtype': np.uint8,\n",
    "        'width': new_width,\n",
    "        'height': new_height,\n",
    "        'count': 3,  # Set count to 3 for RGB image\n",
    "        'crs': crs,\n",
    "        'transform': new_transform,\n",
    "    }\n",
    "\n",
    "    # Transpose the image data to match the expected shape (3, new_height, new_width)\n",
    "    resized = np.transpose(resized, (2, 0, 1))\n",
    "\n",
    "    # Create a new GeoTIFF file with the updated georeferencing and rescaled data\n",
    "    with rio.open(output_tiff, 'w', **profile) as dst:\n",
    "        dst.write(resized)\n",
    "            \n",
    "    # Return the path to the saved rescaled GeoTIFF\n",
    "    return output_tiff\n",
    "\n",
    "# Specify the path to the directory containing the original GeoTIFF files\n",
    "data = c['path']['raw_data']\n",
    "\n",
    "# Specify the directory where you want to save the new rescaled GeoTIFF files\n",
    "output_dir = c['path']['raw_data_rescaled']\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through all TIFF files in the data directory\n",
    "for tif_image_path in tqdm(glob.glob(data + '\\\\' + '*.tif')):\n",
    "    # Call the save_rescaled function to rescale and save each TIFF file\n",
    "    path = save_rescaled(tif_image_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To Tiles:**\n",
    "\n",
    "After reducing the spatial resolution, the resized data needs to be divided into tiles, each with a resolution not exceeding 1000x1000. This is necessary for the Detectree library, which selects 1% of these tiles to effectively represent the entire dataset for labeling and training the model (explained in detail later).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tiles(rescled_path, output_dir, tile_dim= tuple(c['tile']['dim'])):  \n",
    "    \"\"\"\n",
    "    Split a rescaled GeoTIFF image into smaller tiles and save them as separate GeoTIFF files.\n",
    "\n",
    "    Parameters:\n",
    "    - rescled_path (str): The path to the rescaled GeoTIFF image to be split into tiles.\n",
    "    - output_dir (str): The directory where the individual tiles will be saved.\n",
    "    - tile_dim (tuple, optional): The dimensions of each tile in pixels as (width, height). Default is (268, 365).\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the input GeoTIFF file\n",
    "    with rio.open(rescled_path) as src:\n",
    "        # Get metadata and profile information\n",
    "        profile = src.profile\n",
    "        transform = src.transform\n",
    "\n",
    "        # Calculate tile dimensions\n",
    "        tile_height = tile_dim[1]\n",
    "        tile_width = tile_dim[0]\n",
    "\n",
    "        # Get the shape (height and width) of the input GeoTIFF using OpenCV\n",
    "        img_shape = cv2.imread(rescled_path).shape\n",
    "\n",
    "        # Iterate through rows and columns to create tiles\n",
    "        for row in range(img_shape[1] // tile_width):\n",
    "            for col in range(img_shape[0] // tile_height):\n",
    "                # Calculate the window for the current tile\n",
    "                window = Window(row * tile_width, col * tile_height, tile_width, tile_height)\n",
    "\n",
    "                # Read the data for the current tile\n",
    "                tile_data = src.read(window=window)\n",
    "\n",
    "                # Calculate the transform for the current tile\n",
    "                tile_transform = src.window_transform(window)\n",
    "\n",
    "                # Create a new profile for the current tile\n",
    "                tile_profile = src.profile.copy()\n",
    "                tile_profile.update(width=tile_width, height=tile_height, transform=tile_transform)\n",
    "\n",
    "                # Generate a file path for the current tile\n",
    "                tile_path = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(rescled_path))[0]}_{row}_{col}.tif\")\n",
    "\n",
    "                # Write the tile data as a new GeoTIFF with its own georeferencing\n",
    "                with rio.open(tile_path, 'w', **tile_profile) as dst:\n",
    "                    dst.write(tile_data)\n",
    "\n",
    "    #print(\"Tiles created successfully.\")  # Print a message indicating successful tile creation\n",
    "\n",
    "# Define the directory where the rescaled images are saved\n",
    "data = output_dir\n",
    "\n",
    "# Define the directory where you want to save the tiles\n",
    "output_dir = c['path']['output_dir_for_tiles']\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Iterate through all TIFF files in the 'data' directory\n",
    "for tif_image_path in tqdm(glob.glob(data + '*.tif')):\n",
    "    # Call the 'to_tiles' function to split each rescaled image into tiles remember all the tiles must be at the same size. Therefore the Geotiff's resolution in data directory must be devisible by the tile's resulution.\n",
    "    to_tiles(tif_image_path, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select tiles likely to have trees** \n",
    "\n",
    "Selecting tiles likely to have trees is a vital step. To improve training efficiency and accuracy, it's best to choose tiles where trees are likely to be present. For instance, in the Porto Santo Project, out of 12,000 tiles, 9,000 were sea tiles, showing only the sea and no trees. To differentiate between tiles that can contain trees (‘land tiles’) and sea tiles, vector data from OpenStreetMap, representing the sea around Porto Santo, was used. In different projects, a similar approach might be needed for other types of tiles, such as desert tiles or tiles showing large lakes. \n",
    " \n",
    "In this step, a fixed script can be used alongside the user's action of creating polygons for areas without trees. Specifically, the user can utilize QGIS, a popular geographic information system software, to create polygons representing regions devoid of trees. By doing so, the software can then distinguish between areas with trees and those without, aiding in the accurate selection of tiles likely to have trees for further analysis and processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the shapefile containing polygons of non-tree areas (e.g., water bodies)\n",
    "shapefile_path_of_areas_non_tree_polygons = c['path']['shapefile_of_non_tree_areas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12350/12350 [09:54<00:00, 20.78it/s]\n"
     ]
    }
   ],
   "source": [
    "def is_tile_intersects_with_object(tile_path ,polylines):\n",
    "    # Open the GeoTIFF image specified by 'tile_path' using 'rasterio'\n",
    "    with rasterio.open(tile_path) as src:\n",
    "         # Get the georeferenced transform\n",
    "        transform = src.transform\n",
    "\n",
    "        # Get the image width and height\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "\n",
    "        # Calculate the coordinates of the four corners of the image\n",
    "        bottom_left = transform * (0, height)\n",
    "        bottom_right = transform * (width, height)\n",
    "        top_left = transform * (0, 0)\n",
    "        top_right = transform * (width, 0)\n",
    "\n",
    "        # Create a polygon from the coordinates of the four corners\n",
    "        image_polygon = Polygon([bottom_left, bottom_right, top_right, top_left])\n",
    "\n",
    "        # Iterate through each polyline in the 'polylines' DataFrame\n",
    "        for row in polylines.itertuples():\n",
    "            # Get the LineString geometry from the row\n",
    "            polyline = row[-1]\n",
    "\n",
    "            # Check if the tile intersects with the polyline\n",
    "            if polyline.intersects(image_polygon):\n",
    "                return True\n",
    "        \n",
    "        # If there are no intersections with any polyline, return False\n",
    "        return False\n",
    "    \n",
    "def is_tile_within_object(tile_path, polygons):\n",
    "    # Initialize a counter to keep track of polygon intersections\n",
    "    counter = 0\n",
    "    \n",
    "    # Open the GeoTIFF file specified by 'tile_path' using 'rasterio'\n",
    "    with rasterio.open(tile_path) as src:\n",
    "         # Get the georeferenced transform\n",
    "        transform = src.transform\n",
    "\n",
    "        # Get the image width and height\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "\n",
    "        # Calculate the coordinates of the four corners of the image\n",
    "        bottom_left = transform * (0, height)\n",
    "        bottom_right = transform * (width, height)\n",
    "        top_left = transform * (0, 0)\n",
    "        top_right = transform * (width, 0)\n",
    "\n",
    "        # Create a polygon from the coordinates of the four corners\n",
    "        image_polygon = Polygon([bottom_left, bottom_right, top_right, top_left])\n",
    "\n",
    "        # Iterate through each polygon in the 'polygons' DataFrame\n",
    "        for row in polygons.itertuples():\n",
    "            # Get the LineString geometry from the row\n",
    "            polygon = row[-1]\n",
    "\n",
    "            # Check if the tile is entirely within the polygon\n",
    "            if image_polygon.within(polygon):\n",
    "                return True\n",
    "            # Check if the tile intersects with the polygon\n",
    "            elif image_polygon.intersects(polygon):\n",
    "                counter += 1\n",
    "\n",
    "    # If the counter is greater than 1, there is at least one intersection\n",
    "    if counter > 1:\n",
    "        return True\n",
    "    \n",
    "    # If there are no intersections, return False\n",
    "    return False\n",
    "\n",
    "\n",
    "# List to store tiles within non-tree areas\n",
    "non_tree_areas_tiles = []\n",
    "\n",
    "# List to store tiles intersecting both tree and non-tree areas\n",
    "tiles_between_areas = []\n",
    "\n",
    "# List to store tiles within tree areas\n",
    "tree_area_tiles = []\n",
    "\n",
    "# Load non-tree area polygons from the shapefile\n",
    "areas_non_tree_polygons = gpd.read_file(shapefile_path_of_areas_non_tree_polygons)\n",
    "\n",
    "# Iterate through each tile in the specified directory\n",
    "for tile_path in tqdm(glob.glob(output_dir + '*tif')):\n",
    "    # Check if the tile is within non-tree areas\n",
    "    if is_tile_within_object(tile_path, areas_non_tree_polygons):\n",
    "        non_tree_areas_tiles.append(tile_path)\n",
    "    # Check if the tile intersects with both tree and non-tree areas\n",
    "    elif is_tile_intersects_with_object(tile_path, areas_non_tree_polygons):\n",
    "        tiles_between_areas.append(tile_path)\n",
    "    # If the tile is outside non-tree areas, consider it within tree areas\n",
    "    else:\n",
    "        tree_area_tiles.append(tile_path)\n",
    "\n",
    "\n",
    "#saving the paths' lists as a pickle files for future use.\n",
    "with open('tree_area_tiles.pkl', 'wb') as f:\n",
    "    pickle.dump(tree_area_tiles, f)\n",
    "\n",
    "with open('tiles_between_areas.pkl', 'wb') as f:\n",
    "    pickle.dump(tiles_between_areas, f)\n",
    "\n",
    "with open('non_tree_areas_tiles.pkl', 'wb') as f:\n",
    "    pickle.dump(non_tree_areas_tiles, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training using Detectree Library (Pythonic Library):**\n",
    "\n",
    "For additional details about the Detectree library, you can visit the following link: https://github.com/martibosch/detectree. This repository provides in-depth information and resources related to the library, including documentation and usage guidelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the training tiles from the tiled aerial imagery dataset\n",
    "# Using the TrainingSelector class from the Detectree library\n",
    "ts = dtr.TrainingSelector(img_filepaths= tree_area_tiles)\n",
    "# Split the dataset into training and testing sets using the 'cluster-I' method\n",
    "split_df = ts.train_test_split(method='cluster-I')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Selection for labeling, Data lableing and Model Training:**\n",
    "\n",
    "The Detectree tree library automatically chooses 1% of the tiles that most accurately represent the entire set of tiles for user labeling. The 1% tiles should be labeled by the user. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_filepath</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_B3_rescaled_14_17.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_B3_rescaled_20_15.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_B3_rescaled_7_12.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_B4_rescaled_9_6.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C2_rescaled_16_4.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C2_rescaled_20_14.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C2_rescaled_21_18.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_10_6.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_17_11.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_20_6.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_24_2.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_2_2.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_4_0.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_4_6.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_4_8.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_C3_rescaled_6_3.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D1_rescaled_21_9.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D1_rescaled_25_1.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D2_rescaled_13_8.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D2_rescaled_15_4.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D2_rescaled_21_6.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D2_rescaled_3_1.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_D2_rescaled_3_3.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>tiles\\PORTO_SANTO_IMG_E2_rescaled_1_5.tif</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     img_filepath  train\n",
       "113   tiles\\PORTO_SANTO_IMG_B3_rescaled_14_17.tif   True\n",
       "204   tiles\\PORTO_SANTO_IMG_B3_rescaled_20_15.tif   True\n",
       "343    tiles\\PORTO_SANTO_IMG_B3_rescaled_7_12.tif   True\n",
       "805     tiles\\PORTO_SANTO_IMG_B4_rescaled_9_6.tif   True\n",
       "1001   tiles\\PORTO_SANTO_IMG_C2_rescaled_16_4.tif   True\n",
       "1071  tiles\\PORTO_SANTO_IMG_C2_rescaled_20_14.tif   True\n",
       "1094  tiles\\PORTO_SANTO_IMG_C2_rescaled_21_18.tif   True\n",
       "1245   tiles\\PORTO_SANTO_IMG_C3_rescaled_10_6.tif   True\n",
       "1345  tiles\\PORTO_SANTO_IMG_C3_rescaled_17_11.tif   True\n",
       "1409   tiles\\PORTO_SANTO_IMG_C3_rescaled_20_6.tif   True\n",
       "1451   tiles\\PORTO_SANTO_IMG_C3_rescaled_24_2.tif   True\n",
       "1480    tiles\\PORTO_SANTO_IMG_C3_rescaled_2_2.tif   True\n",
       "1507    tiles\\PORTO_SANTO_IMG_C3_rescaled_4_0.tif   True\n",
       "1522    tiles\\PORTO_SANTO_IMG_C3_rescaled_4_6.tif   True\n",
       "1524    tiles\\PORTO_SANTO_IMG_C3_rescaled_4_8.tif   True\n",
       "1557    tiles\\PORTO_SANTO_IMG_C3_rescaled_6_3.tif   True\n",
       "1905   tiles\\PORTO_SANTO_IMG_D1_rescaled_21_9.tif   True\n",
       "1924   tiles\\PORTO_SANTO_IMG_D1_rescaled_25_1.tif   True\n",
       "1997   tiles\\PORTO_SANTO_IMG_D2_rescaled_13_8.tif   True\n",
       "2016   tiles\\PORTO_SANTO_IMG_D2_rescaled_15_4.tif   True\n",
       "2090   tiles\\PORTO_SANTO_IMG_D2_rescaled_21_6.tif   True\n",
       "2132    tiles\\PORTO_SANTO_IMG_D2_rescaled_3_1.tif   True\n",
       "2137    tiles\\PORTO_SANTO_IMG_D2_rescaled_3_3.tif   True\n",
       "2294    tiles\\PORTO_SANTO_IMG_E2_rescaled_1_5.tif   True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This line filters and displays the tiles that should be labeled (training set)\n",
    "split_df[split_df['train'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to store the training tiles\n",
    "train_tiles_dir = c['path']['train_tiles_dir']\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(train_tiles_dir, exist_ok=True)\n",
    "\n",
    "# Copy training tiles to the specified directory\n",
    "for tile_path in split_df[split_df['train'] == True]['img_filepath']:\n",
    "    shutil.copy(tile_path, train_tiles_dir + os.path.basename(tile_path))\n",
    "\n",
    "root_dir = ''\n",
    "images_dir = train_tiles_dir\n",
    "masks_dir = 'masks\\\\'\n",
    "os.makedirs(masks_dir, exist_ok= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!**\n",
    "\n",
    "Before continuing with the code you have to make masks of the training tiles (you can use qgis or gimp).\n",
    "\n",
    "The training tiles are waiting for you in the training tiles directory\n",
    "\n",
    "Create masks only for the tiles that has tree in them and save them in the masks directory **with the same name as the original tile**. \n",
    "\n",
    "The following code will automaticly detect missing masks and generate blank masks (for tiles without trees). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(root_dir = '', images_dir = c['path']['train_tiles_dir'], masks_dir = c['path']['masks_dir']):\n",
    "    # List to store matching filenames of tiles and masks\n",
    "    matching_files = []\n",
    "\n",
    "    # Iterate through tiles and masks, match filenames, and store in matching_files list\n",
    "    for tile_path in glob.glob(root_dir + images_dir + '*tif'):\n",
    "        for mask_path in glob.glob(root_dir + masks_dir + '*tif'):\n",
    "            if os.path.basename(tile_path) == os.path.basename(mask_path):\n",
    "                matching_files.append(os.path.basename(tile_path))\n",
    "\n",
    "    # Process tiles and masks\n",
    "    for tile_path in glob.glob(root_dir + images_dir + '*tif'):\n",
    "        # Check if the tile doesn't have a corresponding mask\n",
    "        if os.path.basename(tile_path) not in matching_files:\n",
    "            # Create a black mask\n",
    "            img = np.zeros(cv2.imread(root_dir + images_dir + os.path.basename(tile_path))[:,:,0].shape)\n",
    "            data = np.dstack((img, img, img)).astype('uint8')\n",
    "            \n",
    "            # Save the mask in RGB format\n",
    "            tifffile.imwrite(\n",
    "                root_dir + masks_dir + os.path.basename(tile_path),\n",
    "                data,\n",
    "                photometric='rgb',\n",
    "                bitspersample=8,\n",
    "                tile=(32, 32),\n",
    "                planarconfig=1\n",
    "            )\n",
    "            \n",
    "            # Preserve geospatial information from the original tile\n",
    "            with rio.open(tile_path) as src:\n",
    "                source_transform = src.transform\n",
    "                source_crs = src.crs\n",
    "            \n",
    "            # Open the mask and preserve its geospatial information\n",
    "            with rio.open(root_dir + masks_dir + os.path.basename(tile_path), 'r+') as dst:\n",
    "                dst.transform = source_transform\n",
    "                dst.crs = source_crs\n",
    "        else:\n",
    "            # Load the mask and convert it to binary (0 and 255)\n",
    "            img = cv2.imread(root_dir + masks_dir + os.path.basename(tile_path))[:,:,0]\n",
    "            img = np.where(img != 0, 255, 0)\n",
    "            \n",
    "            # Save the mask in RGB format\n",
    "            data = np.dstack((img, img, img)).astype('uint8')\n",
    "            tifffile.imwrite(\n",
    "                root_dir + masks_dir + os.path.basename(tile_path),\n",
    "                data,\n",
    "                photometric='rgb',\n",
    "                bitspersample=8,\n",
    "                tile=(32, 32),\n",
    "                planarconfig=1\n",
    "            )\n",
    "            \n",
    "            # Preserve geospatial information from the original tile\n",
    "            with rio.open(tile_path) as src:\n",
    "                source_transform = src.transform\n",
    "                source_crs = src.crs\n",
    "            \n",
    "            # Open the mask and preserve its geospatial information\n",
    "            with rio.open(root_dir + masks_dir + os.path.basename(tile_path), 'r+') as dst:\n",
    "                dst.transform = source_transform\n",
    "                dst.crs = source_crs\n",
    "\n",
    "create_masks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start this code and grab a beer it is going to take a while...**\n",
    "\n",
    "the model will be trained and saved for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a tree/non-tree pixel classfier\n",
    "clf = dtr.ClassifierTrainer().train_classifier(\n",
    "    split_df=split_df, response_img_dir= c['path']['masks_dir'])\n",
    "\n",
    "#save the model in case of a crash or something or future use\n",
    "with open('tree_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict tree and grass locations and shapefile generation for each tile**\n",
    "\n",
    "you should see the results in the results folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('results', exist_ok= True)\n",
    "subprocess.run(['python', 'multiprocess_tree_and_grass.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict tree and grass locations (not necessary), sometimes it might be completely useless for example in the PortoSanto Project**\n",
    "\n",
    "also, in order to use this part of the algorithm you have to make sure that the items in the following shapefile ('multipolygons') are MultiPolygon type class.\n",
    "you can learn more here: https://geopandas.org/en/stable/docs/user_guide/data_structures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the shapefile containing multiple polygons (seas)\n",
    "multipolygons = gpd.read_file(c['path']['shapefile_of_tiny_water_bodies_or_smalll_area_without_trees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_masks_of_between_areas():    \n",
    "    # Ignore the NotGeoreferencedWarning from rasterio\n",
    "    warnings.filterwarnings(\"ignore\", category=rio.errors.NotGeoreferencedWarning)\n",
    "\n",
    "    # Load a list of tile paths from a pickle file\n",
    "    with open('tiles_between_areas.pkl', 'rb') as f:\n",
    "        tiles_between_areas = pickle.load(f)\n",
    "\n",
    "    # Create a directory to store the coastline masks if it doesn't exist\n",
    "    directory = 'coustline_tiles_masks\\\\' \n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    # Initialize a MultiPolygon to store merged geometries\n",
    "    multipolygon_s = multipolygons.iloc[0]['geometry']\n",
    "\n",
    "    # Iterate through rows of the multipolygons GeoDataFrame and merge the geometries\n",
    "    for row in multipolygons.itertuples():\n",
    "        geom = row[-1]\n",
    "        # Merge the geometries into a single MultiPolygon\n",
    "        multipolygon_s = multipolygon_s.union(geom)\n",
    "\n",
    "    # Convert the merged MultiPolygon to a GeoJSON-like mapping\n",
    "    multipolygon_json = mapping(multipolygon_s)\n",
    "\n",
    "    # Process each tile path\n",
    "    for path in tqdm(tiles_between_areas):\n",
    "        with rio.open(path) as src:\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "\n",
    "            # Create a mask for the tile using the merged MultiPolygon\n",
    "            mask = np.where(geometry_mask([multipolygon_json], out_shape=src.shape, transform=transform, invert=True) == True, 1, 0)\n",
    "\n",
    "        # Define the destination name for the mask TIFF file\n",
    "        dst_name = directory + os.path.splitext(os.path.basename(path))[0] + '.tif'\n",
    "\n",
    "        # Save the mask as a TIFF file\n",
    "        tifffile.imwrite(dst_name, mask.astype('uint8') * 255)\n",
    "\n",
    "        # Open the created TIFF file for read/write and set georeferencing information\n",
    "        with rio.open(dst_name, mode='r+') as dst:\n",
    "            dst.transform = transform\n",
    "            dst.crs = crs\n",
    "\n",
    "make_masks_of_between_areas()\n",
    "subprocess.run(['python', 'multiproccess for tiles_between_areas.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create one shapefile of tree locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_false_points(current_tile_with_trees ,shapefile_where_trees_cannot_exist):\n",
    "    # Initialize a boolean mask for false points, initially all True\n",
    "    true_points_mask = np.ones(len(current_tile_with_trees), dtype=bool)\n",
    "    \n",
    "    # Iterate through rows in the shapefile_where_trees_cannot_exist DataFrame\n",
    "    for row in shapefile_where_trees_cannot_exist.itertuples():\n",
    "        # Extract the polygon geometry from the row\n",
    "        polygon = row[-1]\n",
    "        \n",
    "        # Iterate through rows in the current_tile_with_trees DataFrame\n",
    "        for tile_points_row in current_tile_with_trees.itertuples():\n",
    "            # Extract the point geometry and its row index from the row\n",
    "            point = tile_points_row[-1]\n",
    "            point_index = tile_points_row[0]\n",
    "            \n",
    "            # Check if the point is within the polygon\n",
    "            if point.within(polygon):\n",
    "                # If it is within the polygon, append its row index to the list\n",
    "                true_points_mask[i] = False\n",
    "    \n",
    "    # Return a new DataFrame containing only rows not in the false_points_index\n",
    "    return current_tile_with_trees.iloc[true_points_mask]\n",
    "\n",
    "# Read the shapefile containing polygons where trees cannot exist\n",
    "shapefile_of_water_bodies_or_locations_where_trees_cannot_exist = c['path']['shapefile_of_tiny_water_bodies_or_smalll_area_without_trees']\n",
    "\n",
    "# Create an empty GeoDataFrame to store the resulting tree points\n",
    "shapefile_trees = gpd.GeoDataFrame()\n",
    "\n",
    "# Iterate through folders and files in the 'results' directory\n",
    "for folder, _, data in tqdm(os.walk('results')):\n",
    "    if len(data) != 0:\n",
    "        # Read the GeoDataFrame containing all tree points for the current tile\n",
    "        all_tile_points = gpd.read_file(f'{glob.glob(folder + \"/*trees.shp\")[0]}')\n",
    "        \n",
    "        # Clean false points from the current tile using the provided function\n",
    "        true_tile_point = clean_false_points(all_tile_points, shapefile_of_water_bodies_or_locations_where_trees_cannot_exist)\n",
    "        \n",
    "        # Concatenate the resulting true tree points to the shapefile_trees\n",
    "        shapefile_trees = pd.concat([shapefile_trees, true_tile_point])\n",
    "# Save the final shapefile containing the cleaned tree points\n",
    "shapefile_trees.to_file(r'trees.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create one shapefile of grass locations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:05, 15.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty GeoDataFrame to store the grass polygons\n",
    "shapefile_grass = gpd.GeoDataFrame()\n",
    "\n",
    "# Iterate through folders and files in the 'results' directory\n",
    "for folder, _, data in tqdm(os.walk('results')):\n",
    "    if len(data) != 0:\n",
    "        try:\n",
    "            # Concatenate the GeoDataFrame from the current folder's 'grass.shp' file\n",
    "            shapefile_grass = pd.concat([shapefile_grass, gpd.read_file(f'{folder}\\\\grass.shp')])\n",
    "        except:\n",
    "            print (folder)\n",
    "            \n",
    "# Save the final shapefile containing the cleaned grass polygons\n",
    "shapefile_grass.to_file(r'grass.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
